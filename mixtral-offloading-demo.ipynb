{"cells":[{"cell_type":"markdown","source":["利用約12G GPU RAM (T4 GPU 16G) 即可offloading mistral 8x7b model"],"metadata":{"id":"utGoDYL3apyX"}},{"cell_type":"markdown","metadata":{"id":"OW1moHJ1TdhO"},"source":["# Mixtral in Colab\n","\n","Welcome! In this notebook you can run [Mixtral8x7B-Instruct](https://huggingface.co/mistralai/Mixtral-8x7B-v0.1) with decent generation speed **right in Google Colab or on a consumer-grade GPU**. This was made possible by quantizing the original model in mixed precision and implementing a MoE-specific offloading strategy.\n","\n","To learn more, read our [tech report](https://arxiv.org/abs/2312.17238) or check out the [repo](https://github.com/dvmazur/mixtral-offloading) on GitHub."]},{"cell_type":"markdown","metadata":{"id":"2-dvAX_hKZT4"},"source":["One will need approximately 16 GB of VRAM and 11 GB of RAM to run this notebook and generate somewhat long texts.\n","\n","\n","<details>\n","\n","<summary>How to balance between RAM and GPU VRAM usage</summary>\n","\n","You can balance between RAM and GPU VRAM usage by changing <code>offload_per_layer</code> variable in the <a href=\"#scrollTo=_mIpePTMFyRY&line=10&uniqifier=1\">Initialize model</a> section. Increasing <code>offload_per_layer</code> will decrease GPU VRAM usage, increase RAM usage and decrease generation speed. Decreasing <code>offload_per_layer</code> will have the opposite effect.\n","\n","Note that this notebook should run normally in Google Colab with <code>offload_per_layer = 4</code>, but may crush with other values. However, if you run this somewhere else, you're free to play with this variable.\n","</details>"]},{"cell_type":"markdown","metadata":{"id":"Y8MhvkC7TKEL"},"source":["## Install and import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f7qY7ebqX7T7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1da78ffc-e53f-4ae2-9681-a46813c69c3d"},"outputs":[{"output_type":"stream","name":"stdout","text":["/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m852.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m671.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/124.2 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/124.2 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n","\u001b[?25h"]}],"source":["# fix numpy in colab\n","import numpy\n","from IPython.display import clear_output\n","\n","# fix triton in colab\n","!export LC_ALL=\"en_US.UTF-8\"\n","!export LD_LIBRARY_PATH=\"/usr/lib64-nvidia\"\n","!export LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs\"\n","!ldconfig /usr/lib64-nvidia\n","\n","!git clone https://github.com/dvmazur/mixtral-offloading.git --quiet\n","!cd mixtral-offloading && pip install -q -r requirements.txt\n","!huggingface-cli download lavawolfiee/Mixtral-8x7B-Instruct-v0.1-offloading-demo --quiet --local-dir Mixtral-8x7B-Instruct-v0.1-offloading-demo\n","\n","clear_output()"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385},"executionInfo":{"elapsed":5523,"status":"error","timestamp":1704874059654,"user":{"displayName":"daucheng lyu","userId":"10574303180162034414"},"user_tz":-480},"id":"GgpjnV7fV49W","outputId":"42c36c1d-e12b-4260-ebc6-f8c63b0715b1"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'hqq'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-50cf5337a341>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhqq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseQuantizeConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msnapshot_download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hqq'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import sys\n","\n","sys.path.append(\"mixtral-offloading\")\n","import torch\n","from torch.nn import functional as F\n","from hqq.core.quantize import BaseQuantizeConfig\n","from huggingface_hub import snapshot_download\n","from IPython.display import clear_output\n","from tqdm.auto import trange\n","from transformers import AutoConfig, AutoTokenizer\n","from transformers.utils import logging as hf_logging\n","\n","from src.build_model import OffloadConfig, QuantConfig, build_model"]},{"cell_type":"markdown","metadata":{"id":"OkSYibHcTQsH"},"source":["## Initialize model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240,"referenced_widgets":["69227b73e988495cb3480b9b275d51bc","2abe13ca9e744290806fc93d2f807992","22e1e5e278a24c269f784d08d4e8ade9","c69087798c564976b7119e2fcf88ad10","884f0cf1dfc14d51b7096f2e4f6910ea","f73de455c95c4cb589f0b377cc6b99c1","76430c7206f54013ae35288908a8fde8","91ad96f9dc2a4a8cae7be3e66ac1c2c3","bc9ba9fa1166497f89adb5b8e3bec520","3daeb024b6fc471f88962e451ac9e19e","bb24a31966b74e2093787500fdb23aa6","cec990fa800a40b483f0a99b04972034","ccb0a643aa574281b23770a8d5f79425","3a8083fa2e5f443ba5a2234b95c37f41","4d0961fe066f42bc8e57bb4ab0bff7d3","ddb92ae57686447fabceaaff0a190eda","454e0f815cfb421c941800c66945796e","fe39e17c93e842ab89e9bf2b99d9a25f","61a5fb3bf17c4f8984f7d9f6f66613ae","a237d3d8b33e467faff414c695874405","8681a96a587c496eb97193af1b4090e1","b033d17fa626496782df6d8f25d70322"]},"executionInfo":{"elapsed":445583,"status":"ok","timestamp":1704783338778,"user":{"displayName":"daucheng lyu","userId":"10574303180162034414"},"user_tz":-480},"id":"_mIpePTMFyRY","outputId":"8054ed18-da1d-497c-8a4b-dbe1e36c2abe"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69227b73e988495cb3480b9b275d51bc","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/720 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/init.py:412: UserWarning: Initializing zero-element tensors is a no-op\n","  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cec990fa800a40b483f0a99b04972034","version_major":2,"version_minor":0},"text/plain":["Loading experts:   0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model_name = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n","quantized_model_name = \"lavawolfiee/Mixtral-8x7B-Instruct-v0.1-offloading-demo\"\n","state_path = \"Mixtral-8x7B-Instruct-v0.1-offloading-demo\"\n","\n","config = AutoConfig.from_pretrained(quantized_model_name)\n","\n","device = torch.device(\"cuda:0\")\n","\n","##### Change this to 5 if you have only 12 GB of GPU VRAM #####\n","offload_per_layer = 4\n","# offload_per_layer = 5\n","###############################################################\n","\n","num_experts = config.num_local_experts\n","\n","offload_config = OffloadConfig(\n","    main_size=config.num_hidden_layers * (num_experts - offload_per_layer),\n","    offload_size=config.num_hidden_layers * offload_per_layer,\n","    buffer_size=4,\n","    offload_per_layer=offload_per_layer,\n",")\n","\n","\n","attn_config = BaseQuantizeConfig(\n","    nbits=4,\n","    group_size=64,\n","    quant_zero=True,\n","    quant_scale=True,\n",")\n","attn_config[\"scale_quant_params\"][\"group_size\"] = 256\n","\n","\n","ffn_config = BaseQuantizeConfig(\n","    nbits=2,\n","    group_size=16,\n","    quant_zero=True,\n","    quant_scale=True,\n",")\n","quant_config = QuantConfig(ffn_config=ffn_config, attn_config=attn_config)\n","\n","\n","model = build_model(\n","    device=device,\n","    quant_config=quant_config,\n","    offload_config=offload_config,\n","    state_path=state_path,\n",")"]},{"cell_type":"markdown","metadata":{"id":"Z4hBFYtPTUzT"},"source":["## Run the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Zf4GkspecSm8"},"outputs":[],"source":["from transformers import TextStreamer\n","\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n","past_key_values = None\n","sequence = None\n","\n","seq_len = 0\n","while True:\n","  print(\"User: \", end=\"\")\n","  user_input = input()\n","  print(\"\\n\")\n","\n","  user_entry = dict(role=\"user\", content=user_input)\n","  input_ids = tokenizer.apply_chat_template([user_entry], return_tensors=\"pt\").to(device)\n","\n","  if past_key_values is None:\n","    attention_mask = torch.ones_like(input_ids)\n","  else:\n","    seq_len = input_ids.size(1) + past_key_values[0][0][0].size(1)\n","    attention_mask = torch.ones([1, seq_len - 1], dtype=torch.int, device=device)\n","\n","  print(\"Mixtral: \", end=\"\")\n","  result = model.generate(\n","    input_ids=input_ids,\n","    attention_mask=attention_mask,\n","    past_key_values=past_key_values,\n","    streamer=streamer,\n","    do_sample=True,\n","    temperature=0.9,\n","    top_p=0.9,\n","    max_new_tokens=512,\n","    pad_token_id=tokenizer.eos_token_id,\n","    return_dict_in_generate=True,\n","    output_hidden_states=True,\n","  )\n","  print(\"\\n\")\n","\n","  sequence = result[\"sequences\"]\n","  past_key_values = result[\"past_key_values\"]"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"22e1e5e278a24c269f784d08d4e8ade9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_91ad96f9dc2a4a8cae7be3e66ac1c2c3","max":720,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bc9ba9fa1166497f89adb5b8e3bec520","value":720}},"2abe13ca9e744290806fc93d2f807992":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f73de455c95c4cb589f0b377cc6b99c1","placeholder":"​","style":"IPY_MODEL_76430c7206f54013ae35288908a8fde8","value":"config.json: 100%"}},"3a8083fa2e5f443ba5a2234b95c37f41":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_61a5fb3bf17c4f8984f7d9f6f66613ae","max":32,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a237d3d8b33e467faff414c695874405","value":32}},"3daeb024b6fc471f88962e451ac9e19e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"454e0f815cfb421c941800c66945796e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d0961fe066f42bc8e57bb4ab0bff7d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8681a96a587c496eb97193af1b4090e1","placeholder":"​","style":"IPY_MODEL_b033d17fa626496782df6d8f25d70322","value":" 32/32 [01:29&lt;00:00,  2.79s/it]"}},"61a5fb3bf17c4f8984f7d9f6f66613ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69227b73e988495cb3480b9b275d51bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2abe13ca9e744290806fc93d2f807992","IPY_MODEL_22e1e5e278a24c269f784d08d4e8ade9","IPY_MODEL_c69087798c564976b7119e2fcf88ad10"],"layout":"IPY_MODEL_884f0cf1dfc14d51b7096f2e4f6910ea"}},"76430c7206f54013ae35288908a8fde8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8681a96a587c496eb97193af1b4090e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"884f0cf1dfc14d51b7096f2e4f6910ea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91ad96f9dc2a4a8cae7be3e66ac1c2c3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a237d3d8b33e467faff414c695874405":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b033d17fa626496782df6d8f25d70322":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb24a31966b74e2093787500fdb23aa6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc9ba9fa1166497f89adb5b8e3bec520":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c69087798c564976b7119e2fcf88ad10":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3daeb024b6fc471f88962e451ac9e19e","placeholder":"​","style":"IPY_MODEL_bb24a31966b74e2093787500fdb23aa6","value":" 720/720 [00:00&lt;00:00, 38.8kB/s]"}},"ccb0a643aa574281b23770a8d5f79425":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_454e0f815cfb421c941800c66945796e","placeholder":"​","style":"IPY_MODEL_fe39e17c93e842ab89e9bf2b99d9a25f","value":"Loading experts: 100%"}},"cec990fa800a40b483f0a99b04972034":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ccb0a643aa574281b23770a8d5f79425","IPY_MODEL_3a8083fa2e5f443ba5a2234b95c37f41","IPY_MODEL_4d0961fe066f42bc8e57bb4ab0bff7d3"],"layout":"IPY_MODEL_ddb92ae57686447fabceaaff0a190eda"}},"ddb92ae57686447fabceaaff0a190eda":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f73de455c95c4cb589f0b377cc6b99c1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe39e17c93e842ab89e9bf2b99d9a25f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}