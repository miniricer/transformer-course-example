{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM7nIUgpkmFSNQzrUngCT5c"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["How to Import Files from Google Drive to Colab\n","參考[這裏](https://saturncloud.io/blog/how-to-import-files-from-google-drive-to-colab/)\n","\n","*   Step 1: Mount Your Google Drive\n","*   Step 2: Locate the File You Want to Import ([img](https://saturncloud.io/images/blog/files-to-colab.png))\n"],"metadata":{"id":"2Ucv7Solw1Sw"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import cross_val_score\n","import torch\n","import transformers as ppb\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"lzO24IbavKBt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["下載之前的 [clean_data_segment.pkl](https://github.com/miniricer/topic_model_example/blob/master/data_my/clean_data_segment.pkl) 檔案\n","\n","並上傳到個人的google drive"],"metadata":{"id":"h0_Dizx80Zf7"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"kFHFdAf7zi3I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["這裏修改你的路徑"],"metadata":{"id":"l3NcyJgaz1rR"}},{"cell_type":"code","source":["df = pd.read_pickle('/content/drive/MyDrive/clean_data_segment.pkl')\n","df.head(3)"],"metadata":{"id":"M1W_UlBCwqGC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["將 topics 轉爲數字， 成爲label"],"metadata":{"id":"zfD449qz1Dlz"}},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","labelencoder = LabelEncoder()\n","df['labels'] = labelencoder.fit_transform(df['topics'])\n","df.head(3)"],"metadata":{"id":"vpA8J_7Isu-b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","ax = sns.countplot(x=\"topics\",data=df)"],"metadata":{"id":"aVUz5CJbyIpv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# For DistilBERT:\n","model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-chinese')\n","\n","# Load pretrained model/tokenizer\n","tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n","model = model_class.from_pretrained(pretrained_weights)"],"metadata":{"id":"yfE0n7Z5pcaG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_txt = '豪 大雨 造成 南部 地區 重大 災情 除了 淹水 災民 收拾 家園 很 辛苦 也 要'\n","tokens = tokenizer.tokenize(sample_txt)\n","token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","print(f' Sentence: {sample_txt}')\n","print(f'   Tokens: {tokens}')\n","print(f'Token IDs: {token_ids}')"],"metadata":{"id":"cfnF5OaPx97w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["BERT 有 512 長度的限制， 所以先限定字數在200以内"],"metadata":{"id":"jCmak5Rb0Thr"}},{"cell_type":"code","source":["df200 = df.loc[(df['num_word'] <= 200)]"],"metadata":{"id":"4kdGSw3DqM0g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df200.shape"],"metadata":{"id":"qIjcJt5Wqo53"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized = df200['contents'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"],"metadata":{"id":"hguSKcqFkBWQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_len = 0\n","for i in tokenized.values:\n","    if len(i) > max_len:\n","        max_len = len(i)\n","\n","padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"],"metadata":{"id":"Qmi7S3YyllAp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.array(padded).shape"],"metadata":{"id":"geGKy0sil5tp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["attention_mask = np.where(padded != 0, 1, 0)\n","attention_mask.shape"],"metadata":{"id":"SUvmSYY6oN-F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids = torch.tensor(padded)\n","attention_mask = torch.tensor(attention_mask)\n","\n","with torch.no_grad():\n","    last_hidden_states = model(input_ids, attention_mask=attention_mask)"],"metadata":{"id":"ubNytfCMoU60"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = last_hidden_states[0][:,0,:].numpy()"],"metadata":{"id":"q1VAnZqesff5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = df200['labels']"],"metadata":{"id":"2gBfHcf9splI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"],"metadata":{"id":"lFExTcpPt_9T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lr_clf = LogisticRegression()\n","lr_clf.fit(train_features, train_labels)"],"metadata":{"id":"jp_IEmquuONL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lr_clf.score(test_features, test_labels)"],"metadata":{"id":"B11EnELEuW_i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.dummy import DummyClassifier\n","clf = DummyClassifier()\n","\n","scores = cross_val_score(clf, train_features, train_labels)\n","print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"],"metadata":{"id":"IDk4m-IUuaTD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["[參考](https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/)"],"metadata":{"id":"l_rmVJIIu3Gb"}}]}